{"version":3,"file":"static/webpack/static/development/pages/design-reading.js.be1962ab114dbcd22429.hot-update.js","sources":["webpack:///./pages/design-reading.md"],"sourcesContent":["/* @jsx mdx */\n  import React from 'react'\n  import { mdx } from '@mdx-js/react'\n  /* @jsx mdx */\nimport Container from '../components/Container'\nimport PostHeader from '../components/PostHeader'\n\nconst makeShortcode = name => function MDXDefaultShortcode(props) {\n  console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\")\n  return <div {...props}/>\n};\n\nconst layoutProps = {\n  \n};\nconst MDXLayout = \"wrapper\"\nexport default function MDXContent({\n  components,\n  ...props\n}) {\n  return <MDXLayout {...layoutProps} {...props} components={components} mdxType=\"MDXLayout\">\n\n    <Container mdxType=\"Container\">\n  <PostHeader title=\"Design Reading\" published=\"12-04-2020\" mdxType=\"PostHeader\" />\n      <p>{`The following is a list of articles, technologies, videos, and resources that\nhave changed the shape of how I see the world in a significant way over the\nlast few years. Each concept or piece of technology is something I recommend\ndesigners have at least a cursory understanding of.`}</p>\n      <h2>{`Generative Design`}</h2>\n      <img src='https://mrmrs.cc/photos/site/dreamcatcher-output.jpeg' />\n      <small style={{\n        fontSize: '14px',\n        fontStyle: 'italic',\n        color: \"#666\"\n      }}>Generative design output. Source: Arup</small>\n      <p>{`Generative design can be utilized to spend more time curating and reviewing designs than manually constructing them for review. Adding constraints to generative algorithms can allow for the automated generation of solutions that might not be quickly intuited or explored due to the sheer manual labor to construct them all. Curating options at the scale generative design allows for can help you more rapidly understand relationships between values. `}</p>\n      <p><a parentName=\"p\" {...{\n          \"href\": \"http://www.possibilityspace.org/tutorial-generative-possibility-space/\"\n        }}>{`Generative vs. Possibility Space`}</a><br />{`\n`}<a parentName=\"p\" {...{\n          \"href\": \"http://www.possibilityspace.org/tutorial-sampling/index.html\"\n        }}>{`Sampling`}</a><br />{`\n`}<a parentName=\"p\" {...{\n          \"href\": \"https://www.arup.com/projects/additive-manufacturing\"\n        }}>{`Design method for critical structural steel elements`}</a><br />{`\n`}<a parentName=\"p\" {...{\n          \"href\": \"https://www.arup.com/-/media/arup/files/pdf-downloads/additive_manufacturing_report_for_iass_21015.pdf\"\n        }}>{`Optimizing Structural Building Elements in Metal by using Additive Manufacturing`}</a><br />{`\n`}<a parentName=\"p\" {...{\n          \"href\": \"http://rene.jon.gold\"\n        }}>{`Rene by Jon Gold`}</a><br />{`\n`}<a parentName=\"p\" {...{\n          \"href\": \"https://autodeskresearch.com/projects/dreamcatcher\"\n        }}>{`Project Dreamcatcher - Autodesk`}</a><br /></p>\n      <h2>{`Computational Design`}</h2>\n      <p>{`Within design - what can we compute? What can we not? What are the physics of user interfaces?`}</p>\n      <p><a parentName=\"p\" {...{\n          \"href\": \"https://ubiquity.acm.org/article.cfm?id=3132087\"\n        }}>{`Computational Design - Article`}</a><br />{`\n`}<a parentName=\"p\" {...{\n          \"href\": \"https://www.amazon.com/Codify-Parametric-Computational-Landscape-Architecture/dp/1138125032\"\n        }}>{`Codify: Parametric and Computational Design in Landscape Architecture`}</a><br /></p>\n      <p><a parentName=\"p\" {...{\n          \"href\": \"https://www.amazon.com/Computational-Design-Neil-Leach/dp/7560873332/ref=pd_sbs_14_img_2/141-7105120-1627543?_encoding=UTF8&pd_rd_i=7560873332&pd_rd_r=20f13f7e-2ba7-4aac-b354-fb12b1b5f12e&pd_rd_w=o2nlD&pd_rd_wg=8Vg5V&pf_rd_p=5cfcfe89-300f-47d2-b1ad-a4e27203a02a&pf_rd_r=ZTPC0D02K9X871QNM1J7&psc=1&refRID=ZTPC0D02K9X871QNM1J7\"\n        }}>{`Computational Design - Book`}</a><br /></p>\n      <p>{`\"The prevailing planning tools inherently lack feedback mechanisms, or the capability to facilitate the processing of information and to learn from input/output relationships.\"`}</p>\n      <p>{`\"Parametric or Generative design has the potential to overcome the mass-produced, homogenous, and disorienting sterility of 20th century architecture. It has the potential to re-associate with historic practice, and amplifying assimilated knowledge. \"`}</p>\n      <p>{`\"Indeed, if all the potential solutions are already out there and it is simply a question of searching for them, it potentially undermines the whole notion of the 'design genius'. Further, if there is any creativity in that process it lies surely in the creative us of such search engines. The designer emerges less as the demiurgic top down controller and more as someone who harnesses the productive capacity of informational processes. As I have noted elsewhere: 'Of the many potentialities afforded by the the computer, one of the most significant is its capacity to poperate as a search engine. If, then, we think through the logic of search in the context of 'design', what such an approach suggests is that if all possible solutions already exist, it is simply a quest of defining a set of constraints and conducting a search, and then selecting on of the many outcomes. The potential implications of this are far reaching.\"`}</p>\n      <h2>{`Shaders`}</h2>\n      <p>{`If you only learn about one thing - make sure it's shaders. `}</p>\n      <p><a parentName=\"p\" {...{\n          \"href\": \"https://gamedevelopment.tutsplus.com/tutorials/a-beginners-guide-to-coding-graphics-shaders--cms-23313\"\n        }}>{`Beginners Guide to Coding Graphics Shaders`}</a><br />{`\n\"A shader's sole purpose is to return four numbers: r, g, b,and a. That's all it ever does or can do.\"`}</p>\n      <p><a parentName=\"p\" {...{\n          \"href\": \"https://thebookofshaders.com\"\n        }}>{`The Book of Shaders`}</a><br />{`\n\"This book is about the revolutionary computational technique, fragment shaders, that is taking digitally generated images to the next level. You can think of it as the equivalent of Gutenberg's press for graphics.\"`}</p>\n      <p><a parentName=\"p\" {...{\n          \"href\": \"https://twitter.com/iquilezles/status/1154611032188342272?s=20\"\n        }}>{`Procedural shader example`}</a><br />{`\n`}<a parentName=\"p\" {...{\n          \"href\": \"https://www.youtube.com/watch?v=Cfe5UQ-1L9Q\"\n        }}>{`Decoding procedural shader`}</a><br />{`\n`}<a parentName=\"p\" {...{\n          \"href\": \"https://sparkar.facebook.com/ar-studio/learn/documentation/docs/visual-programming/visual-shaders/\"\n        }}>{`Visual Shaders`}</a><br />{`\n`}<a parentName=\"p\" {...{\n          \"href\": \"https://www.freecodecamp.org/news/how-you-can-use-ai-ar-and-webgl-shaders-to-assist-the-visually-impaired-3df5bdf3b3e2/\"\n        }}>{`How You Can Use AI, AR, and WebGL Shaders to Assist the Visually Impaired`}</a></p>\n      <h2>{`Language Models`}</h2>\n      <p><a parentName=\"p\" {...{\n          \"href\": \"https://openai.com/blog/better-language-models/\"\n        }}>{`GPT-2: Better language Models and Their Implications`}</a><br />{`\n\"GPT-2 is a large transformer-based language model with 1.5 billion parameters, trained on a dataset of 8 million web pages. GPT-2 is trained with a simple objective: predict the next word, given all of the previous words within some text...On language tasks like question answering, reading comprehension, summarization, and translation, GPT-2 begins to learn these tasks from the raw text, using no task-specific training data.\"`}</p>\n      <p><a parentName=\"p\" {...{\n          \"href\": \"https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html\"\n        }}>{`T5`}</a><br /></p>\n      <p><a parentName=\"p\" {...{\n          \"href\": \"https://tabnine.com/blog/deep/\"\n        }}>{`Tabnine`}</a><br />{`\n\"Deep TabNine is trained on around 2 million files from GitHub. During training, its goal is to predict each token given the tokens that come before it. To achieve this goal, it learns complex behaviour, such as type inference in dynamically typed languages.\"`}</p>\n      <h2>{`Wave Function Collapse`}</h2>\n      <p>{`Largely used in game design, WFC is a powerful component of constraint based procedural design. Can be used to\ndesign everything from poems to 3D worlds.`}</p>\n      <p><a parentName=\"p\" {...{\n          \"href\": \"https://robertheaton.com/2018/12/17/wavefunction-collapse-algorithm/\"\n        }}>{`The Wavefunction Collapse Algorithm explained very clearly`}</a><br />{`\n`}<a parentName=\"p\" {...{\n          \"href\": \"http://www.procjam.com/tutorials/wfc/\"\n        }}>{`Generating Worlds With Wave Function Collapse`}</a><br />{`\n`}<a parentName=\"p\" {...{\n          \"href\": \"https://github.com/mxgmn/WaveFunctionCollapse\"\n        }}>{`WFC Algorithm on GitHub`}</a><br />{`\n`}<a parentName=\"p\" {...{\n          \"href\": \"https://www.youtube.com/watch?v=0bcZb-SsnrA\"\n        }}>{`Bad North + WFC`}</a><br />{`\n`}<a parentName=\"p\" {...{\n          \"href\": \"https://oskarstalberg.com/game/planet/planet.html\"\n        }}>{`Interactive demo`}</a></p>\n      <h2>{`Generative Adversarial Networks (GANs)`}</h2>\n      <p>{`\"The most important one, in my opinion, is adversarial training (also called GAN for Generative Adversarial Networks).This, and the variations that are now being proposed is the most interesting idea in the last 10 years in ML, in my opinion.\"\n`}{`â€“`}{` Yann LeCun, Director of AI Research at Facebook and Professor at NYU`}</p>\n      <img src=\"https://github.com/junyanz/CycleGAN/raw/master/imgs/horse2zebra.gif\" />\n      <p><a parentName=\"p\" {...{\n          \"href\": \"https://en.wikipedia.org/wiki/Generative_adversarial_network\"\n        }}>{`Wikipedia definition`}</a><br />{`\n`}<a parentName=\"p\" {...{\n          \"href\": \"https://machinelearningmastery.com/what-is-cyclegan/\"\n        }}>{`What is CycleGAN`}</a><br />{`\n`}<a parentName=\"p\" {...{\n          \"href\": \"https://junyanz.github.io/CycleGAN/\"\n        }}>{`CycleGAN`}</a><br />{`\n`}<a parentName=\"p\" {...{\n          \"href\": \"https://arxiv.org/abs/1905.01164\"\n        }}>{`SinGAN: Learning a Generative Model from a Single Natural Image`}</a><br />{`\n`}<a parentName=\"p\" {...{\n          \"href\": \"https://drive.google.com/file/d/17ki_YAL1k5CaHHP3pIBFWvw-ztF4CCPP/view\"\n        }}>{`3D Photography using Context-aware Layered Depth Inpainting`}</a><br /></p>\n      <h2>{`Deep / Reinforcement Learning`}</h2>\n      <p>{`There is a certain type of creativity that emerges when computers can attempt millions of attempts at optimizing towards a goal within a given set of constraints. Shown below is a crane that's had it's gripping function disabled - learning to pick up a cube from a platform.`}</p>\n      <iframe width=\"728\" height=\"320\" src=\"https://www.youtube.com/embed/_5Y1hSLhYdY\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n      <p><a parentName=\"p\" {...{\n          \"href\": \"https://arxiv.org/pdf/1803.03453.pdf\"\n        }}>{`Surprising Creativity of AI`}</a><br />{`\n`}<a parentName=\"p\" {...{\n          \"href\": \"https://deepmind.com/blog/article/AlphaStar-Grandmaster-level-in-StarCraft-II-using-multi-agent-reinforcement-learning\"\n        }}>{`Multi-agent Reinforcement Learning`}</a>{`\n`}<a parentName=\"p\" {...{\n          \"href\": \"https://towardsdatascience.com/how-to-teach-an-ai-to-play-games-deep-reinforcement-learning-28f9b920440a\"\n        }}>{`How to teach AI to play Games: Deep Reinforcement Learning`}</a></p>\n    </Container>\n    </MDXLayout>;\n}\n\n;\nMDXContent.isMDXComponent = true;\n  "],"mappings":";;;;;;;;;;;;;;;;;;;;;;;AAAA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AAAA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAHA;AACA;AAIA;AAGA;AACA;AAGA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAIA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAHA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAGA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAGA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAGA;AAAA;AACA;AADA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AAEA;AACA;;;;A","sourceRoot":""}